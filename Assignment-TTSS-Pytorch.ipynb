{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment TTSS - Pytorch.ipynb","provenance":[{"file_id":"19K7yIh96IkiefYCvm5eWlEl05r1AxF5x","timestamp":1575375428641}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"SmZ1gdJTRah3","colab_type":"code","outputId":"59a86877-46ef-4e68-edda-5a947749db13","executionInfo":{"status":"ok","timestamp":1576646044422,"user_tz":-420,"elapsed":2909,"user":{"displayName":"Quân Nguyễn Trương Đình","photoUrl":"","userId":"02678085703007000153"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#import thu vien va set moi truong gpu\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.autograd import Variable\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","plt.ion()\n","use_gpu = torch.cuda.is_available()\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","if use_gpu:\n","    print(\"Using CUDA\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using CUDA\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K4hPWNBhcUt3","colab_type":"code","outputId":"dffa7694-7400-45db-94f1-175b6e443c04","executionInfo":{"status":"ok","timestamp":1576646076472,"user_tz":-420,"elapsed":18303,"user":{"displayName":"Quân Nguyễn Trương Đình","photoUrl":"","userId":"02678085703007000153"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["#load dataset from drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SYf7ChEWnf0Q","colab_type":"code","outputId":"72602117-23ee-4515-d7ab-117e8a0d8db0","executionInfo":{"status":"ok","timestamp":1576646079604,"user_tz":-420,"elapsed":1208,"user":{"displayName":"Quân Nguyễn Trương Đình","photoUrl":"","userId":"02678085703007000153"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","os.listdir('../content/')"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['.config', 'drive', 'sample_data']"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"TnVS_6YUcr1y","colab_type":"code","colab":{}},"source":["#unzip folder and extract all to 'temp' folder\n","import zipfile\n","zip_ref=zipfile.ZipFile('../content/drive/My Drive/Dataset/assignment.zip','r')\n","zip_ref.extractall('temp')\n","zip_ref.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9oIcNFhic6iz","colab_type":"code","colab":{}},"source":["#view list folder in .zip file\n","# os.listdir('../content/temp/test1/')\n","\n","# !pwd\n","# !cd temp/\n","# !rm -r temp/data/\n","# os.listdir('../content/temp/')\n","# !mkdir -p -v data_test/test1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G_je6pwH0As9","colab_type":"code","colab":{}},"source":["# cp -avr temp/test1/ data_test/test1/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JpCzrRQxdTL6","colab_type":"code","outputId":"c59367cd-4241-4117-d229-54defaca5b6f","executionInfo":{"status":"ok","timestamp":1576646131356,"user_tz":-420,"elapsed":984,"user":{"displayName":"Quân Nguyễn Trương Đình","photoUrl":"","userId":"02678085703007000153"}},"colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["import time\n","\n","start_time = time.time()\n","# preproccessing images\n","dset_dir = 'temp'\n","# val_dir = '..content/temp/validation'\n","# test = 'content/temp/test1'\n","TRAIN = 'train'\n","VAL = 'validation'\n","TEST = 'test1'\n","\n","#resize all image into (224,224,3) \n","data_transforms = {\n","    TRAIN: transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","    ]),\n","    VAL: transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","    ]),\n","    TEST: transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","    ])\n","}\n","\n","#label image\n","image_datasets = {\n","    x: datasets.ImageFolder(\n","        os.path.join(dset_dir, x), \n","        transform=data_transforms[x]\n","    )\n","    for x in [TRAIN, VAL]\n","}\n","\n","#load image\n","dataloaders = {\n","    x: torch.utils.data.DataLoader(\n","        image_datasets[x], batch_size=32,\n","        shuffle=True, num_workers=4\n","    )\n","    for x in [TRAIN, VAL]\n","}\n","\n","dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, VAL]}\n","\n","for x in [TRAIN, VAL]:\n","    print(\"Loaded {} images under {}\".format(dataset_sizes[x], x))\n","    \n","print(\"Classes: \")\n","class_names = image_datasets[TRAIN].classes\n","print(image_datasets[TRAIN].classes)\n","\n","end_time = time.time()\n","print('Time to load Images to Tensor: %f ms' % ((end_time - start_time) * 1000))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Loaded 19652 images under train\n","Loaded 5348 images under validation\n","Classes: \n","['cat', 'dog']\n","Time to load Images to Tensor: 70.363998 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PZ3T2xBNhbA8","colab_type":"code","outputId":"d5fd47fc-d711-4fe6-9493-8726c4e05c9f","executionInfo":{"status":"ok","timestamp":1576646199616,"user_tz":-420,"elapsed":33108,"user":{"displayName":"Quân Nguyễn Trương Đình","photoUrl":"","userId":"02678085703007000153"}},"colab":{"base_uri":"https://localhost:8080/","height":790}},"source":["start_time = time.time()\n","\n","\n","#build model\n","vgg16 = models.vgg16(pretrained = True)\n","print(vgg16.classifier[6].out_features) # 1000 \n","# print(vgg16.classifier[1])\n","\n","# Freeze training for all layers\n","for param in vgg16.features.parameters():\n","    param.require_grad = False\n","\n","# Newly created modules have require_grad=True by default\n","num_features = vgg16.classifier[6].out_features\n","features = list(vgg16.classifier.children())[0:3] # get just 2 layer first\n","features.extend([nn.Linear(in_features=4096, out_features=2, bias=True)])# Add our layer with 1 outputs\n","vgg16.classifier = nn.Sequential(*features) # Replace the model classifier\n","vgg16 = vgg16.to('cuda:0')\n","# criterion = nn.CrossEntropyLoss()\n","# optimizer = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9,weight_decay= 1e-6,nesterov=True) #torch.optim.Adam(vgg16.parameters(), lr=0.002, amsgrad=True)\n","# scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1) #torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[500,1000,1500], gamma=0.5)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9,weight_decay= 1e-6,nesterov=True)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n","#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(vgg16)\n","\n","end_time = time.time()\n","print('Time to build model in Pytorch: %f ms' % ((end_time - start_time) * 1000))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n","100%|██████████| 528M/528M [00:23<00:00, 23.3MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["1000\n","VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=2, bias=True)\n","  )\n",")\n","Time to build model in Pytorch: 31899.269342 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ltOYL_3qCx_5","colab_type":"code","outputId":"631ea09e-ce7d-46c1-a297-cc40c91ea55d","executionInfo":{"status":"ok","timestamp":1575538559960,"user_tz":-420,"elapsed":1596,"user":{"displayName":"Quân Nguyễn Trương Đình","photoUrl":"","userId":"02678085703007000153"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(torch.cuda.get_device_name(0))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tvxA1y5REe3J","colab_type":"code","outputId":"6ddfc3d6-d5ea-40f4-9e97-3e6bca566f53","executionInfo":{"status":"ok","timestamp":1576647237521,"user_tz":-420,"elapsed":940048,"user":{"displayName":"Quân Nguyễn Trương Đình","photoUrl":"","userId":"02678085703007000153"}},"colab":{"base_uri":"https://localhost:8080/","height":449}},"source":["start_time = time.time()\n","\n","epochs = 3\n","itr = 1\n","p_itr = 200\n","device='cuda:0'\n","vgg16.train()\n","total_loss = 0\n","loss_list = []#ve do thi\n","acc_list = []#ve do thi\n","time_take = time.time()\n","for epoch in range(epochs):\n","    for samples, labels in dataloaders[TRAIN]:\n","        samples = samples.to(device)\n","        labels  =  labels.to(device)\n","        optimizer.zero_grad()\n","        output = vgg16(samples)\n","        loss = criterion(output, labels)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","        scheduler.step()\n","        \n","        \n","        if itr%p_itr == 0:#lap moi 200 samples \n","            pred = torch.argmax(output, dim=1)\n","            correct = pred.eq(labels)\n","            acc = torch.mean(correct.float())\n","            time_take = time.time() - time_take\n","            print('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Accuracy: {:.3f}, Training complete in {:.0f}m {:.0f}s'.format(epoch+1, epochs, itr, total_loss/p_itr, acc,time_take//60,time_take%60))\n","            loss_list.append(total_loss/p_itr)\n","            acc_list.append(acc)\n","            total_loss = 0\n","        itr += 1\n","        # del outputs, pred\n","end_time = time.time()\n","print('Time to train model in Pytorch: %f ms' % ((end_time - start_time) * 1000))\n","\n","torch.cuda.empty_cache()\n","plt.plot(loss_list, label='loss')\n","plt.plot(acc_list, label='accuracy')\n","plt.legend()\n","plt.title('training loss and accuracy')\n","plt.show()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[Epoch 1/3] Iteration 200 -> Train Loss: 0.3271, Accuracy: 0.875, Training complete in 1m 42s\n","[Epoch 1/3] Iteration 400 -> Train Loss: 0.3225, Accuracy: 0.938, Training complete in 26277439m 58s\n","[Epoch 1/3] Iteration 600 -> Train Loss: 0.3227, Accuracy: 0.812, Training complete in 3m 24s\n","[Epoch 2/3] Iteration 800 -> Train Loss: 0.3149, Accuracy: 0.906, Training complete in 26277441m 40s\n","[Epoch 2/3] Iteration 1000 -> Train Loss: 0.3146, Accuracy: 0.844, Training complete in 5m 5s\n","[Epoch 2/3] Iteration 1200 -> Train Loss: 0.3252, Accuracy: 1.000, Training complete in 26277443m 22s\n","[Epoch 3/3] Iteration 1400 -> Train Loss: 0.3169, Accuracy: 0.906, Training complete in 6m 47s\n","[Epoch 3/3] Iteration 1600 -> Train Loss: 0.3260, Accuracy: 0.906, Training complete in 26277445m 3s\n","[Epoch 3/3] Iteration 1800 -> Train Loss: 0.3234, Accuracy: 0.906, Training complete in 8m 29s\n","Time to train model in Pytorch: 938329.384804 ms\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndBGRiFBCFxGJCCV0EZGI+H8byWAqHi3F9gAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"UepjKl11ziQI","colab_type":"code","outputId":"d77cae2f-c82c-4176-b51e-ec30b8beb6cc","executionInfo":{"status":"error","timestamp":1575508752394,"user_tz":-420,"elapsed":2178,"user":{"displayName":"Quân Nguyễn Trương Đình","photoUrl":"","userId":"02678085703007000153"}},"colab":{"base_uri":"https://localhost:8080/","height":354}},"source":["# # filename_pth = 'vgg16_with_torch_catdogDS.pth'\n","# # torch.save(vgg16.state_dict(), filename_pth)\n","\n","# # test_transform = transforms.Compose([\n","# #     transforms.Resize((128,128)),\n","# #     transforms.ToTensor()\n","# # ])\n","\n","\n","# # x: datasets.ImageFolder(\n","# #         os.path.join(dset_dir, x), \n","# #         transform=data_transforms[x]\n","# #     )\n","# # dataloaders = {\n","# #     x: torch.utils.data.DataLoader(\n","# #         image_datasets[x], batch_size=32,\n","# #         shuffle=True, num_workers=4\n","# #     )\n","# #     for x in [TRAIN, VAL]\n","# # }\n","# test_dataset = datasets.ImageFolder(os.path.join('data_test','test1'),transform=data_transforms[TEST])\n","# # print(test_dataset)\n","# testloader = torch.utils.data.DataLoader(test_dataset,batch_size=32,shuffle=True,num_workers=4)\n","# print(testloader)\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-273e3d3eef6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_test'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# print(test_dataset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtestloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    207\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                                           is_valid_file=is_valid_file)\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m     91\u001b[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001b[1;32m     92\u001b[0m                                             target_transform=target_transform)\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m_find_classes\u001b[0;34m(self, dir)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# Faster and available in Python 3.5 and above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_test/test1'"]}]},{"cell_type":"code","metadata":{"id":"h6mTt0DK9aNv","colab_type":"code","colab":{}},"source":["imsize = 256\n","loader = transforms.Compose([transforms.Resize(imsize), transforms.ToTensor()])\n","from PIL import Image\n","def image_loader(image_name):\n","    \"\"\"load image, returns cuda tensor\"\"\"\n","    image = Image.open('../content/temp/test1/'+image_name)\n","    image = loader(image).float()\n","    image = Variable(image, requires_grad=True)\n","    image = image.unsqueeze(0)  #this is for VGG, may not be needed for ResNet\n","    return image.to('cuda:0')  #assumes that you're using GPU"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WJkIwhV-AHPc","colab_type":"code","outputId":"50c9615f-91d6-445d-f484-8ba239eff6de","executionInfo":{"status":"ok","timestamp":1576647419161,"user_tz":-420,"elapsed":16030,"user":{"displayName":"Quân Nguyễn Trương Đình","photoUrl":"","userId":"02678085703007000153"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1oMkkfZX_HhOAlnbmMLTnGtZFejNSQ7uT"}},"source":["start_time = time.time()\n","\n","lst = []\n","lst1=[]\n","ii =0\n","for img in os.listdir('../content/temp/test1/'):\n","  ii+=1\n","  if ii >=100:\n","    break\n","  lst.append((image_loader(img),img))\n","\n","from keras.preprocessing import image\n","vgg16.eval()\n","plt.figure(figsize=(30,20))\n","i = 0\n","for item in lst:\n","  plt.subplot(10,10,i+1)\n","  plt.xticks([])\n","  plt.yticks([])\n","  plt.grid(False)\n","  t = vgg16(item[0])\n","  path='../content/temp/test1/'+str(item[1])\n","  img=image.load_img(path,target_size=(224,224))\n","  img= np.asarray(img)\n","  plt.imshow(img)\n","  img= np.expand_dims(img,axis=0)\n","  pred = torch.argmax(t, dim=1)\n","  if str(pred[0].item()) == '0':\n","      plt.xlabel('Pic '+ str(item[1]) + ': CAT')\n","  else:\n","      plt.xlabel('Pic '+ str(item[1]) + ': DOG')\n","  i+=1\n","\n","end_time = time.time()\n","print('Time to train model in Tensorflow: %f ms' % ((end_time - start_time) * 1000))"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"RbFweR9Rz24E","colab_type":"code","outputId":"767fd59f-bfdc-48fa-eeb7-4f2e254fe30e","executionInfo":{"status":"error","timestamp":1575362730737,"user_tz":-420,"elapsed":3339,"user":{"displayName":"Vutrntin Trần","photoUrl":"","userId":"09625665838867431861"}},"colab":{"base_uri":"https://localhost:8080/","height":968}},"source":["# vgg16.eval()\n","# fn_list = []\n","# pred_list = []\n","\n","# for x, fn in testloader:\n","#     # print(fn)\n","#     with torch.no_grad():\n","#         x = x.to('cuda:0')\n","#         output = vgg16(x)\n","#         pred = torch.argmax(output, dim=1)\n","        \n","#         fn_list += [n[:-4] for n in fn]\n","#         pred_list += [p.item() for p in pred]\n","\n","# submission = pd.DataFrame({\"id\":fn_list, \"label\":pred_list})\n","# submission.to_csv('preds.csv', index=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f7ee6c66898>>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n","Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f7ee6c66898>>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n","    w.join()\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n","    assert self._parent_pid == os.getpid(), 'can only join a child process'\n","AssertionError: can only join a child process\n","Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f7ee6c66898>>\n","Traceback (most recent call last):\n","    w.join()\n","Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f7ee6c66898>>\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n","    assert self._parent_pid == os.getpid(), 'can only join a child process'\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n","AssertionError: can only join a child process\n","    w.join()\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n","    assert self._parent_pid == os.getpid(), 'can only join a child process'\n","    w.join()\n","  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 122, in join\n","AssertionError: can only join a child process\n","    assert self._parent_pid == os.getpid(), 'can only join a child process'\n","AssertionError: can only join a child process\n"],"name":"stderr"},{"output_type":"stream","text":["1\n"],"name":"stdout"},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-82-193b0e66d4fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mfn_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mpred_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-82-193b0e66d4fb>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mfn_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mpred_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: dimension specified as 0 but tensor has no dimensions"]}]},{"cell_type":"code","metadata":{"id":"_0O7iVKc4r6a","colab_type":"code","colab":{}},"source":["# #danh gia model\n","# def eval_model(vgg, criterion):\n","#     since = time.time()\n","#     avg_loss = 0\n","#     avg_acc = 0\n","#     loss_test = 0\n","#     acc_test = 0\n","    \n","#     test_batches = len(dataloaders[TEST])\n","#     print(\"Evaluating model\")\n","#     print('-' * 10)\n","    \n","#     for i, data in enumerate(dataloaders[TEST]):\n","#         if i % 100 == 0:\n","#             print(\"\\rTest batch {}/{}\".format(i, test_batches), end='', flush=True)\n","\n","#         vgg.train(False)\n","#         vgg.eval()\n","#         inputs, labels = data\n","\n","#         if use_gpu:\n","#             inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n","#         else:\n","#             inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n","\n","#         outputs = vgg(inputs)\n","\n","#         _, preds = torch.max(outputs.data, 1)\n","#         loss = criterion(outputs, labels)\n","\n","#         loss_test += loss.data[0]\n","#         acc_test += torch.sum(preds == labels.data)\n","\n","#         del inputs, labels, outputs, preds\n","#         torch.cuda.empty_cache()\n","        \n","#     avg_loss = loss_test / dataset_sizes[TEST]\n","#     avg_acc = acc_test / dataset_sizes[TEST]\n","    \n","#     elapsed_time = time.time() - since\n","#     print()\n","#     print(\"Evaluation completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n","#     print(\"Avg loss (test): {:.4f}\".format(avg_loss))\n","#     print(\"Avg acc (test): {:.4f}\".format(avg_acc))\n","#     print('-' * 10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gRHuqGWolyfK","colab_type":"text"},"source":[""]}]}